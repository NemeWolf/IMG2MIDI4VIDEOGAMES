{
    "model_params": {
        "features_dim": 84,
        "sequence_length": 16,
        "latent_dim": 96,
        "encoder_lstm_units": [
            56,
            28,
            224
        ],
        "conductor_lstm_units": 112,
        "decoder_lstm_units": 224,
        "recurrent_dropout": 0.2,
        "dropout_rate": 0.35,
        "l2_regularization": 0.00015
    },
    "train_params": {
        "kl_weight": 0.6,
        "epochs": 60,
        "batch_size": 512
    },
    "use_real_augmentation": false,
    "augmentation_factor": 0
}